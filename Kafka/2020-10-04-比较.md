## Kafka与Broker不同

1. 消息定期清理。各个主题设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。
2. 多个消费者可以重复消费同一条消息。
3. Kafka可以在如下情况下自动创建主题：当一个生产者开始往主题写入消息时，当一个消费者开始从主题读取消息时，当任意一个客户端向主题发送元数据请求时。
4. 客户端为了优化网络和磁盘空间，会对消息进行压缩，服务器需要对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存在磁盘上。
5. kafka允许主题的名字为null, Refactor不允许。
6. Kafka的Consumer属于消费者组群。
7. 消费者组群之间允许重复消费消息。![image-20201005132432782](C:\Users\lwl\AppData\Roaming\Typora\typora-user-images\image-20201005132432782.png)
8. Kafka中所有broker都缓存了元数据，因此，客户端可以向任何一个broker发送**元数据请求**，并得到客户端所感兴趣的主题所在分区，每个分区都包含哪些副本，以及哪个副本是首领。因此，consumer需要时不时的向broker发送元数据请求来刷新本地缓存的信息。
9. 

# Kafka的一些Feture

1. Kafka的所有消息保存在磁盘上，存放这些日志片段的目录是通过log.dirs指定的，它是一组用逗号分割的本地文件系统路径。如果指定了多个路径，那么Broker会根据最少使用原则，把统一分区的日志片段保存在同一路径下。要注意：Broker会往拥有最少数据分区的路径新增分区，而不是往拥有最少磁盘空间的路径新增分区。

2. 提供二进制连接协议，即用户直接向Kafka网络端口发送适当的字节序列，就可以实现从Kafka读取消息或往Kafka写消息

3. 用户可以从指定偏移量开始读数据，例如seekToBeginning和seekToEnd

4. 消费者既可以依赖于组群存在，也可以独立存在。

5. 消费者请求数据的时候，可以设置broker返回数据的上限，也可以设置下限。这样可以在主题消息流量不是很大的情况下，减少CPU和网络开销。

6. 日志压缩是Kafka的一个高级特性，因为有了这个特性，Kafka可以用来长时间保存数据。

   

## 问题处理

1. Kafka也需人为设置BrokerID,需要使用者自己保证该ID是唯一的，如果两个broker使用相同的BrokerID，则第二个broker就无法启动。在Broker启动时，它通过创建临时节点把自己的ID注册到Zookeeper。Kafka组件订阅Zookeeper的/brokers/ids路径（broker在Zookeeper上的注册路径），当有broker加入集群或者退出集群时，这些组件就能获得通知。



# Refactor一些可以改进的地方

1. 发送消息长度超过MESSAGE_LENGTH时，返回错误码；
2. Consumer请求的topic不在此broker上，返回相关错误码；



# 日志维护

## 小收获

1. 除了设置socket 外，还需要设置TCP soc ke t 的读写缓冲区，它们的参数分别是net.i.pv4.tcp_wmem和net . i.pv4 . tc p_ wmem 。这些参数的值由3 个整数组成，它们使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于net.core.wmem_max可以和net.core.rmem_max指定的大小。例如，“4096 65536 204800。”表示最小值是4KB、默认值是64KB、最大值是2MB 。根据Kafka 服务器接收流量的实际情况，可能需要设置更高的最大值，为网络连接提供更大的缓冲空间。还有其他一些有用的网络参数。例如， 把net.ipv4.tcp_window_scaling 设为l ，启用TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据可以在服务器端进行缓冲。把net.1.pv4.tcp_max_syn_backlog 设为比默认值1024 更大的值，可以接受更多的井发连接, 把net.core.netdev_max_backlog 设为比默认值1000 更大的值，有助于应对网络流量的爆发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理。
2. 